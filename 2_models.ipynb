{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "hT9WJqbDwO-b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "98V4OdMdMjt6"
   },
   "outputs": [],
   "source": [
    "# Define el path una sola vez\n",
    "path = 'C:/Documents/ME-UNLP/2do trimestre/Machine Learning/TP1/ML_UNLP/data/'\n",
    "\n",
    "# Ruta para la carpeta interna que contiene los archivos CSV\n",
    "path_data = path + 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jr4p7aPMYoD"
   },
   "source": [
    "# Predicting wages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJFRvpJEMb-d"
   },
   "source": [
    "## upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1730959122913,
     "user": {
      "displayName": "María Victoria Mascaró",
      "userId": "07190485167329860905"
     },
     "user_tz": 180
    },
    "id": "q3Nh-QTXMvCv",
    "outputId": "b296e51d-f0a6-4b22-f554-799a70067c4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directorio</th>\n",
       "      <th>secuencia_p</th>\n",
       "      <th>orden</th>\n",
       "      <th>clase</th>\n",
       "      <th>mes</th>\n",
       "      <th>estrato1</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>p6050</th>\n",
       "      <th>p6090</th>\n",
       "      <th>...</th>\n",
       "      <th>y_viaticos_m</th>\n",
       "      <th>y_accidentes_m</th>\n",
       "      <th>y_salarySec_m</th>\n",
       "      <th>y_ingLab_m_ha</th>\n",
       "      <th>y_gananciaNeta_m</th>\n",
       "      <th>y_gananciaNetaAgro_m</th>\n",
       "      <th>y_gananciaIndep_m</th>\n",
       "      <th>y_gananciaIndep_m_hu</th>\n",
       "      <th>y_total_m</th>\n",
       "      <th>y_total_m_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4514331</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4514331</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8404.320312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.620833e+06</td>\n",
       "      <td>8404.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4514332</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4514332</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4514332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32172</th>\n",
       "      <td>4804454</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3345.555664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003667e+06</td>\n",
       "      <td>3345.555664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32173</th>\n",
       "      <td>4804455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25958.333984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.675000e+06</td>\n",
       "      <td>25958.333984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32174</th>\n",
       "      <td>4804455</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32175</th>\n",
       "      <td>4804455</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32176</th>\n",
       "      <td>4804455</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32177 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       directorio  secuencia_p  orden  clase  mes  estrato1  sex  age  p6050  \\\n",
       "0         4514331            1      2      1    1         2    0   29      2   \n",
       "1         4514331            1      1      1    1         2    1   36      1   \n",
       "2         4514332            1      4      1    1         2    1    4      3   \n",
       "3         4514332            1      3      1    1         2    1    7      3   \n",
       "4         4514332            1      1      1    1         2    0   32      1   \n",
       "...           ...          ...    ...    ...  ...       ...  ...  ...    ...   \n",
       "32172     4804454            1      2      1   12         2    0   24      2   \n",
       "32173     4804455            1      1      1   12         3    0   36      1   \n",
       "32174     4804455            1      2      1   12         3    1   41      2   \n",
       "32175     4804455            1      3      1   12         3    1    8      3   \n",
       "32176     4804455            1      4      1   12         3    0    0      3   \n",
       "\n",
       "       p6090  ...  y_viaticos_m  y_accidentes_m  y_salarySec_m  y_ingLab_m_ha  \\\n",
       "0          1  ...           NaN             NaN            NaN            NaN   \n",
       "1          1  ...           NaN             NaN            NaN    8404.320312   \n",
       "2          0  ...           NaN             NaN            NaN            NaN   \n",
       "3          0  ...           NaN             NaN            NaN            NaN   \n",
       "4          1  ...           NaN             NaN            NaN            NaN   \n",
       "...      ...  ...           ...             ...            ...            ...   \n",
       "32172      1  ...           NaN             NaN            NaN    3345.555664   \n",
       "32173      1  ...      500000.0             NaN            NaN   25958.333984   \n",
       "32174      1  ...           NaN             NaN            NaN            NaN   \n",
       "32175      0  ...           NaN             NaN            NaN            NaN   \n",
       "32176      0  ...           NaN             NaN            NaN            NaN   \n",
       "\n",
       "       y_gananciaNeta_m  y_gananciaNetaAgro_m  y_gananciaIndep_m  \\\n",
       "0                   NaN                   NaN                NaN   \n",
       "1                   NaN                   NaN                NaN   \n",
       "2                   NaN                   NaN                NaN   \n",
       "3                   NaN                   NaN                NaN   \n",
       "4                   NaN                   NaN                NaN   \n",
       "...                 ...                   ...                ...   \n",
       "32172               NaN                   NaN                NaN   \n",
       "32173               NaN                   NaN                NaN   \n",
       "32174               NaN                   NaN                NaN   \n",
       "32175               NaN                   NaN                NaN   \n",
       "32176               NaN                   NaN                NaN   \n",
       "\n",
       "       y_gananciaIndep_m_hu     y_total_m  y_total_m_ha  \n",
       "0                       NaN           NaN           NaN  \n",
       "1                       NaN  1.620833e+06   8404.320312  \n",
       "2                       NaN           NaN           NaN  \n",
       "3                       NaN           NaN           NaN  \n",
       "4                       NaN           NaN           NaN  \n",
       "...                     ...           ...           ...  \n",
       "32172                   NaN  1.003667e+06   3345.555664  \n",
       "32173                   NaN  6.675000e+06  25958.333984  \n",
       "32174                   NaN           NaN           NaN  \n",
       "32175                   NaN           NaN           NaN  \n",
       "32176                   NaN           NaN           NaN  \n",
       "\n",
       "[32177 rows x 176 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_data +'df_clean.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6SfbcxENFgL"
   },
   "source": [
    "### Split Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "df[\"log_y\"]=np.log(df[\"y_ingLab_m_ha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[[\"log_y\",\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\", \"sizeFirm\", \"formal\"]]\n",
    "df_subset = df_subset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_subset[[ \"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\", \"sizeFirm\", \"formal\"]]\n",
    "\n",
    "y=df_subset[[\"log_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Modelo\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Specification      RMSE\n",
      "0                                         [sex, age]  0.733238\n",
      "1                           [sex, age, maxEducLevel]  0.635572\n",
      "2                    [sex, age, maxEducLevel, relab]  0.635775\n",
      "3             [sex, age, maxEducLevel, relab, p6050]  0.633572\n",
      "4    [sex, age, maxEducLevel, relab, p6050, college]  0.613097\n",
      "5  [sex, age, maxEducLevel, relab, p6050, college...  0.613097\n",
      "6  [sex, age, maxEducLevel, relab, p6050, college...  0.568538\n",
      "7  [sex, age, maxEducLevel, relab, p6050, college...  0.563018\n",
      "8  [sex, age, age_squared, maxEducLevel, age_educ...  0.586230\n",
      "9  [sex, age, age_squared, maxEducLevel, relab, p...  0.560027\n",
      "Best specification: Specification    [sex, age, age_squared, maxEducLevel, relab, p...\n",
      "RMSE                                                      0.560027\n",
      "Name: 9, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df_subset is your DataFrame\n",
    "X = df_subset[[\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\", \"sizeFirm\", \"formal\"]]\n",
    "y = df_subset[\"log_y\"]  # Assuming log_y is a single column (not a DataFrame)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "\n",
    "\n",
    "# Add interaction and squared terms to the dataset\n",
    "X['age_squared'] = X['age']**2\n",
    "X['age_education'] = X['age'] * X['maxEducLevel']\n",
    "X['firm_formal'] = X['sizeFirm'] * X['formal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define 10 different model specifications\n",
    "specifications = [\n",
    "    [\"sex\", \"age\"],  # Simple model with 2 variables\n",
    "    [\"sex\", \"age\", \"maxEducLevel\"],\n",
    "    [\"sex\", \"age\", \"maxEducLevel\", \"relab\"],\n",
    "    [\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\"],\n",
    "    [\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\"],\n",
    "    [\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\"],\n",
    "    [\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\", \"sizeFirm\"],\n",
    "    [\"sex\", \"age\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\", \"sizeFirm\", \"formal\"],\n",
    "    [\"sex\", \"age\", \"age_squared\", \"maxEducLevel\", \"age_education\", \"firm_formal\"],\n",
    "    [\"sex\", \"age\", \"age_squared\", \"maxEducLevel\", \"relab\", \"p6050\", \"college\", \"depto\", \"sizeFirm\", \"formal\"]\n",
    "]\n",
    "\n",
    "# Evaluate each specification\n",
    "results = []\n",
    "for spec in specifications:\n",
    "    # Extract features for the current specification\n",
    "    X_train_spec = X_train[spec]\n",
    "    X_test_spec = X_test[spec]\n",
    "    \n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_spec, y_train)\n",
    "    \n",
    "    # Make predictions and calculate RMSE\n",
    "    y_pred = model.predict(X_test_spec)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results.append({'Specification': spec, 'RMSE': rmse})\n",
    "\n",
    "# Convert results to a DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Identify the best specification\n",
    "best_spec = results_df.loc[results_df['RMSE'].idxmin()]\n",
    "print(f\"Best specification: {best_spec}\")\n",
    "\n",
    "# Residual Analysis for the Best Model\n",
    "best_features = best_spec['Specification']\n",
    "model = LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3881     1.524112\n",
       "29504    1.315100\n",
       "16647   -1.331929\n",
       "17672    1.206567\n",
       "4725     1.343446\n",
       "           ...   \n",
       "1800    -1.464704\n",
       "12639   -1.185303\n",
       "22395    1.550225\n",
       "670      1.365039\n",
       "4480     1.328455\n",
       "Name: log_y, Length: 109, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual Analysis for the Best Model\n",
    "best_features = best_spec['Specification']\n",
    "model = LinearRegression()\n",
    "model.fit(X_train[best_features], y_train)\n",
    "residuals = y_test - model.predict(X_test[best_features])\n",
    "\n",
    "# Examine residuals distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(residuals, bins=30)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Identify potential outliers\n",
    "outliers = residuals[np.abs(residuals) > 2 * residuals.std()]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ki-d46YewF7E"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Verificar las primeras filas para confirmar la estructura\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Identificar la variable objetivo y las características\n",
    "target = 'y_ingLab_m_ha'  # Ajusta si es necesario\n",
    "X = df[selected_variables]\n",
    "y = df[target]\n",
    "\n",
    "# Separar las columnas numéricas y categóricas\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Columnas numéricas: {numerical_cols}\")\n",
    "print(f\"Columnas categóricas: {categorical_cols}\")\n",
    "\n",
    "# Preprocesamiento: Escalar numéricas y codificar categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyZwtUwkyRmm"
   },
   "source": [
    "Explicación:\n",
    "\n",
    "Carga de Datos: Cargamos el archivo CSV con los datos. Asegúrate de que el archivo se encuentra en el directorio correcto.\n",
    "\n",
    "Identificación de Variables: Definimos y_total_m como la variable objetivo y el resto como características predictoras.\n",
    "\n",
    "Separación de Columnas: Dividimos las columnas en numéricas y categóricas para aplicar diferentes técnicas de preprocesamiento.\n",
    "\n",
    "Preprocesamiento: Utilizamos StandardScaler para escalar las variables numéricas y OneHotEncoder para codificar las variables categóricas.\n",
    "\n",
    "División de Datos: Dividimos los datos en conjuntos de entrenamiento (70%) y prueba (30%) con random_state=123 para reproducibilidad.\n",
    "\n",
    "3(b). Reportar y comparar el desempeño predictivo (RMSE) de al menos diez especificaciones\n",
    "Implementaremos diez modelos de machine learning diferentes y calcularemos el RMSE para cada uno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "\n",
    "Definición de Modelos: Seleccionamos diez modelos diferentes que abarcan desde modelos lineales.\n",
    "\n",
    "Cálculo de RMSE: Calculamos el Error Cuadrático Medio de la Raíz (RMSE) para evaluar el desempeño de cada modelo.\n",
    "\n",
    "Almacenamiento y Ordenamiento: Almacenamos los resultados en un DataFrame y los ordenamos para facilitar la comparación.\n",
    "\n",
    "3(c). Discusión de los resultados i. Sobre el desempeño general de los modelos Observa los RMSE obtenidos para cada modelo en el DataFrame results. Los modelos con menor RMSE tienen un mejor desempeño predictivo. En general, los modelos de ensamble como XGBoost, Gradient Boosting y Random Forest suelen tener un desempeño superior debido a su capacidad para capturar relaciones no lineales y manejar interacciones entre variables.\n",
    "\n",
    "ii. Sobre la especificación con el menor error de predicción Supongamos que XGBoost es el modelo con el menor RMSE. Este modelo es conocido por su eficiencia y precisión en tareas de regresión y clasificación.\n",
    "\n",
    "iii. Explorar observaciones que \"fallaron el objetivo\" Analizaremos los errores de predicción del mejor modelo para identificar posibles outliers o patrones que el modelo no ha capturado adecuadamente.\n",
    "\n",
    "Código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_model_name = results.loc[0, 'Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Crear la pipeline para el mejor modelo\n",
    "best_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', best_model)\n",
    "])\n",
    "\n",
    "# Entrenar el mejor modelo con todo el conjunto de entrenamiento\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calcular los errores de predicción\n",
    "errors = y_test - y_pred_best\n",
    "\n",
    "# Añadir los errores al DataFrame de prueba\n",
    "test_results = X_test.copy()\n",
    "test_results[target] = y_test\n",
    "test_results['Predicted'] = y_pred_best\n",
    "test_results['Error'] = errors\n",
    "\n",
    "# Describir la distribución de errores\n",
    "error_distribution = test_results['Error'].describe()\n",
    "print(\"\\nDistribución de errores de predicción:\\n\")\n",
    "print(error_distribution)\n",
    "\n",
    "# Visualizar la distribución de errores\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(errors, kde=True, bins=30)\n",
    "plt.title(f'Distribución de Errores de Predicción para {best_model_name}')\n",
    "plt.xlabel('Error (Real - Predicho)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# Identificar outliers (errores que están más allá de 3 desviaciones estándar)\n",
    "threshold = 3 * errors.std()\n",
    "outliers = test_results[np.abs(errors) > threshold]\n",
    "\n",
    "print(f\"\\nNúmero de outliers (errores > 3σ): {outliers.shape[0]}\")\n",
    "print(outliers[['Predicted', target, 'Error']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "\n",
    "Selección del Mejor Modelo: Identificamos el modelo con el menor RMSE.\n",
    "\n",
    "Entrenamiento y Predicción: Entrenamos el mejor modelo y realizamos predicciones en el conjunto de prueba.\n",
    "\n",
    "Cálculo de Errores: Calculamos los errores de predicción (Error = y_test - y_pred_best).\n",
    "\n",
    "Distribución de Errores: Analizamos la distribución de los errores para identificar posibles patrones o sesgos.\n",
    "\n",
    "Identificación de Outliers: Definimos outliers como aquellos errores que superan tres veces la desviación estándar. Estos pueden ser casos de interés para DIAN.\n",
    "\n",
    "Interpretación:\n",
    "\n",
    "Distribución de Errores: Una distribución centrada alrededor de cero indica que el modelo no tiene sesgo sistemático. Si hay asimetría o kurtosis elevada, podría indicar problemas en el modelo.\n",
    "\n",
    "Outliers: Las observaciones con errores grandes podrían ser debido a datos atípicos o limitaciones del modelo. Es importante revisar estos casos para determinar si son errores de datos o si el modelo necesita mejoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(d). Validación cruzada Leave-One-Out (LOOCV) Realizaremos LOOCV para los dos modelos con el menor RMSE en la sección anterior y compararemos los resultados con el error en el conjunto de prueba.\n",
    "\n",
    "Nota: LOOCV es computacionalmente intensivo, especialmente con conjuntos de datos grandes y modelos complejos. Asegúrate de tener los recursos necesarios antes de proceder.\n",
    "\n",
    "Código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Seleccionar los dos mejores modelos\n",
    "top_two_models = results.head(2)['Model'].tolist()\n",
    "\n",
    "loocv_results = pd.DataFrame(columns=['Model', 'LOOCV_RMSE'])\n",
    "\n",
    "for name in top_two_models:\n",
    "    model = models[name]\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    # Calcular el RMSE usando cross_val_score con scoring negativo MSE\n",
    "    # LOOCV se implementa estableciendo cv igual al número de muestras\n",
    "    scores = cross_val_score(pipeline, X, y, cv=len(X), scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    # Convertir los scores negativos a RMSE\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    mean_rmse = rmse_scores.mean()\n",
    "\n",
    "    # Almacenar los resultados\n",
    "    loocv_results = loocv_results.append({'Model': name, 'LOOCV_RMSE': mean_rmse}, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"\\nResultados de LOOCV:\\n\")\n",
    "print(loocv_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "\n",
    "Selección de Modelos: Seleccionamos los dos modelos con el menor RMSE.\n",
    "\n",
    "Pipeline: Creamos una Pipeline para cada modelo que incluye el preprocesamiento y el modelo de regresión.\n",
    "\n",
    "Cálculo de LOOCV: Utilizamos cross_val_score con cv=len(X) para realizar LOOCV, lo que implica entrenar y evaluar el modelo para cada observación individualmente.\n",
    "\n",
    "Cálculo de RMSE Promedio: Convertimos los puntajes negativos de MSE a RMSE y calculamos el promedio.\n",
    "\n",
    "Almacenamiento de Resultados: Guardamos los resultados en un DataFrame para comparar.\n",
    "\n",
    "Comparación:\n",
    "\n",
    "RMSE en Conjunto de Prueba vs. LOOCV: Si los RMSE de LOOCV son similares a los del conjunto de prueba, indica que el modelo tiene una buena capacidad de generalización. Diferencias significativas podrían indicar sobreajuste (RMSE de prueba mucho mayor) o subajuste (RMSE de LOOCV mucho mayor).\n",
    "\n",
    "Resumen y Recomendaciones Mejor Modelo: Identifica cuál de los modelos evaluados tiene el menor RMSE y considera su complejidad y tiempo de entrenamiento.\n",
    "\n",
    "Errores de Predicción: Analiza los errores de predicción para entender dónde y por qué el modelo falla, lo que puede guiar mejoras en el preprocesamiento o en la selección de características.\n",
    "\n",
    "Validación Cruzada: La comparación entre el RMSE en el conjunto de prueba y el LOOCV te dará una idea de la estabilidad y robustez del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próximos Pasos:\n",
    "\n",
    "Ajuste de Hiperparámetros: Considera realizar una búsqueda de hiperparámetros (por ejemplo, usando GridSearchCV o RandomizedSearchCV) para optimizar los modelos. Selección de Características: Si tienes muchas características, podrías beneficiarte de técnicas de reducción de dimensionalidad o selección de características. Manejo de Outliers: Decide cómo manejar las observaciones que presentan grandes errores de predicción, ya sea revisando los datos o ajustando el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhM0qYPWynsT"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
